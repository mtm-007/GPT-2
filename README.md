# nanoGPT
- `GPT-2`

# This repo 
- took inspiration and reference from the Great Andrej Karphaty,it is not a direct clone but written as a follow up with his videos and code repo on my own understanding with some modefication
- Andrej Karpathy is the best on educating complex systems by on scaling it down and start from the basic on first principles method

# not a clone
- The reason for not directly forking or cloning andrej Karpathy repo is to learn and experince the pain point when scaling and pushing the limits of code(i.e like `torch.cuda.OutOfMemoryError: CUDA out of memory` errors) those pain points are part of the learning curve, other developers might hate and avoid those but those errors hold the power

# Experiment Tracking
- for experment tracking the repo uses `Wandb` on the alternative  `mlflow` can be used to its fully opensource and open governance   

# torch.compile as pytorch > 2.0
- in the latest commits torch.compile() is used to give some faster training kick back